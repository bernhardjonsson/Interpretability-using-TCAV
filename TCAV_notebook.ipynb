{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5900a9ba",
   "metadata": {},
   "source": [
    "# Running TCAV for Fire Engine Data\n",
    "\n",
    "This is a notebook that shows an example on how to run the TCAV library to predict which concepts are most important in the prediction of the contents of an image. This example focuses on using colors (red, yellow, green and blue) as human interpretable concepts in the prediction of Fire Engine images using GoogleNet.\n",
    "\n",
    "## Installing Packages\n",
    "Make sure to have all the required packages before running by executing the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beae100",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4cdb4f",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "The data used in the TCAV library is split into three categories: \n",
    "> **Targets:** The imagenet object category we are interested in (in this case that is fire engine)\n",
    "\n",
    "> **Concepts:** The human comprehendable concepts used in the analysis\n",
    "\n",
    "> **Random folders:** Random data obtained from imagenet\n",
    "\n",
    "### Classes and Random Folders Data\n",
    "To download the class data and the random folders data, start by downloading the [imagenet dataset](https://www.kaggle.com/competitions/imagenet-object-localization-challenge/data). For the Fire Engine example, the class that was used was `fire engine`. The random folders were also extraced from the same dataset by running the following command:\n",
    "\n",
    "> python random_gen.py\n",
    "\n",
    "ATH SKOÐA BETUR?\n",
    "\n",
    "### Concept Data\n",
    "To get the color concept data used in the Fire Engine example run the following commands (Make sure to change the source_dir argument):\n",
    "\n",
    "> cd tcav/tcav_examples/image_models/imagenet\n",
    "\n",
    "> python download_and_make_datasets.py --source_dir=YOUR_PATH --number_of_images_per_folder=50\n",
    "\n",
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf6be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatically reload all changed code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tcav.activation_generator as act_gen\n",
    "import tcav.cav as cav\n",
    "import tcav.model  as model\n",
    "import tcav.tcav as tcav\n",
    "import tcav.utils as utils\n",
    "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579c682",
   "metadata": {},
   "source": [
    "## Step 1: Defining Parameters and Creating Local Folders\n",
    "\n",
    "In the cell below a few variables are defined that will be used throughout the notebook. \n",
    "\n",
    "**activation_dir:** directory to store activations\n",
    "\n",
    "**cav_dir:** directory to store CAVs\n",
    "\n",
    "**bottlenecks:** the intermediate layers in your model included for TCAV.\n",
    "\n",
    "**target, concepts:** the same as explained in the Downloading Data section above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('REMEMBER TO UPDATE YOUR_PATH (where images, models are)!')\n",
    "  \n",
    "project_dir = 'tcav_dir'\n",
    "# the name of the parent directory that results are stored (only if you want to cache)\n",
    "project_name = 'tcav_class_test'\n",
    "working_dir = \"/tmp/\" + project_dir + '/' + project_name\n",
    "# where activations are stored (only if your act_gen_wrapper does so)\n",
    "activation_dir =  working_dir + '/activations/'\n",
    "# where CAVs are stored. \n",
    "# You can say None if you don't wish to store any.\n",
    "cav_dir = working_dir + '/cavs/'\n",
    "# where the images live.\n",
    "\n",
    "# TODO: replace 'YOUR_PATH' with path to downloaded models and images. \n",
    "source_dir = 'YOUR_PATH'\n",
    "bottlenecks = [ 'mixed3a', 'mixed3b','mixed4a', 'mixed4b','mixed4c','mixed4d','mixed4e','mixed5a','mixed5b', 'logit']  # @param \n",
    "\n",
    "utils.make_dir_if_not_exists(activation_dir)\n",
    "utils.make_dir_if_not_exists(working_dir)\n",
    "utils.make_dir_if_not_exists(cav_dir)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]\n",
    "\n",
    "target = 'fire engine'  \n",
    "concepts = [\"red-c\",\"yellow-c\",\"blue-c\",\"green-c\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9645a",
   "metadata": {},
   "source": [
    "## Step 2: Defining the Model\n",
    "\n",
    "**GRAPH_PATH:** path to where the trained model is stored.\n",
    "\n",
    "**LABEL_PATH:** path to where the labels are stored. Each line contains one class, and they are ordered with respect to their index in the logit layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow session.\n",
    "sess = utils.create_session()\n",
    "\n",
    "# GRAPH_PATH is where the trained model is stored.\n",
    "GRAPH_PATH = source_dir + \"/inception5h/tensorflow_inception_graph.pb\"\n",
    "\n",
    "# LABEL_PATH is where the labels are stored. \n",
    "LABEL_PATH = source_dir + \"/inception5h/imagenet_comp_graph_label_strings.txt\"\n",
    "\n",
    "#Creating the GoogleNet model\n",
    "mymodel = model.GoogleNetWrapper_public(sess,\n",
    "                                        GRAPH_PATH,\n",
    "                                        LABEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170b0a6",
   "metadata": {},
   "source": [
    "# Step 3: \n",
    "SKRIFA MEIRA HÉR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_generator = act_gen.ImageActivationGenerator(mymodel, source_dir, activation_dir, max_examples=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee93326",
   "metadata": {},
   "source": [
    "# Step 4: Run TCAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl\n",
    "absl.logging.set_verbosity(0)\n",
    "num_random_exp=8\n",
    "\n",
    "## only running num_random_exp = 10 to save some time. The paper number are reported for 500 random runs. \n",
    "for alpha in alphas:\n",
    "    alpha = [alpha]\n",
    "    mytcav = tcav.TCAV(sess,\n",
    "                       target,\n",
    "                       concepts,\n",
    "                       bottlenecks,\n",
    "                       act_generator,\n",
    "                       alpha,\n",
    "                       cav_dir=cav_dir,\n",
    "                       num_random_exp=num_random_exp)#10)\n",
    "    print ('Running for: ', alpha,'. This may take a while... Go get coffee!')\n",
    "    results = mytcav.run(run_parallel=False)\n",
    "    utils_plot.plot_results2(results, num_random_exp=num_random_exp, alpha=alpha)\n",
    "    print ('done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
