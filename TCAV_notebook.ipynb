{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5900a9ba",
   "metadata": {},
   "source": [
    "# Running TCAV for Fire Engine Data\n",
    "\n",
    "This is a notebook that shows an example on how to run the TCAV library to predict which concepts are most important in the prediction of the contents of an image. This code obtained from [this](https://github.com/tensorflow/tcav/) git repository and adapted to enable the reproduction of their results. This example focuses on using colors (red, yellow, green and blue) as human interpretable concepts in the prediction of Fire Engine images using GoogleNet.\n",
    "\n",
    "## Installing Packages\n",
    "Make sure to have all the required packages before running by executing the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6beae100",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4cdb4f",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "The data used in the TCAV library is split into three categories: \n",
    "> **Targets:** The imagenet object category we are interested in (in this case that is fire engine)\n",
    "\n",
    "> **Concepts:** The human comprehendable concepts used in the analysis\n",
    "\n",
    "> **Random folders:** Random data obtained from imagenet\n",
    "\n",
    "### Classes and Random Folders Data\n",
    "To download the class data and the random folders data, start by downloading the [imagenet dataset](https://www.kaggle.com/competitions/imagenet-object-localization-challenge/data). For the Fire Engine example, the class that was used was `fire engine`. The random folders were also extraced from the same dataset by running the following command:\n",
    "\n",
    "> python random_gen.py\n",
    "\n",
    "This script runs on the downloaded dataset and extracts random images from downloaded dataset. The number of random folders and picture per folder can be set in the two constant variables in the script.\n",
    "\n",
    "### Concept Data\n",
    "To get the color concept data used in the Fire Engine example run the following commands (Make sure to change the source_dir argument):\n",
    "\n",
    "> python src/download_and_make_datasets.py --source_dir=YOUR_PATH --number_of_images_per_folder=200\n",
    "\n",
    "By running the code above, the entire Broden1_224 dataset is downloaded which is then used to create the color concept data. For each image in the dataset there is another image with the same name and a `_color` postfix. These `_color` images consist of pixels where each pixel has a value representing one of the 11 common color names. Each image was then classified into one of the 11 common colors based on the highest occuring color in the image. A random subset of 200 images representing each color was then added into the corresponding color folders.\n",
    "\n",
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf6be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatically reload all changed code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1a9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tcav.activation_generator as act_gen\n",
    "import tcav.cav as cav\n",
    "import tcav.model  as model\n",
    "import tcav.tcav as tcav\n",
    "import tcav.utils as utils\n",
    "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579c682",
   "metadata": {},
   "source": [
    "## Step 1: Defining Parameters and Creating Local Folders\n",
    "\n",
    "In the cell below a few variables are defined that will be used throughout the notebook. \n",
    "\n",
    "**activation_dir:** directory to store activations\n",
    "\n",
    "**cav_dir:** directory to store CAVs\n",
    "\n",
    "**bottlenecks:** the intermediate layers in your model included for TCAV.\n",
    "\n",
    "**target, concepts:** the same as explained in the Downloading Data section above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686d4591",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('REMEMBER TO UPDATE YOUR_PATH (where images, models are)!')\n",
    "  \n",
    "project_dir = 'tcav_dir'\n",
    "# the name of the parent directory that results are stored (only if you want to cache)\n",
    "project_name = 'tcav_class_test'\n",
    "working_dir = \"/tmp/\" + project_dir + '/' + project_name\n",
    "# where activations are stored (only if your act_gen_wrapper does so)\n",
    "activation_dir =  working_dir + '/activations/'\n",
    "# where CAVs are stored. \n",
    "# You can say None if you don't wish to store any.\n",
    "cav_dir = working_dir + '/cavs/'\n",
    "# where the images live.\n",
    "\n",
    "# TODO: replace 'YOUR_PATH' with path to downloaded models and images. \n",
    "source_dir = 'YOUR_PATH'\n",
    "bottlenecks = [ 'mixed3a', 'mixed3b','mixed4a', 'mixed4b','mixed4c','mixed4d','mixed4e','mixed5a','mixed5b', 'logit']  # @param \n",
    "\n",
    "utils.make_dir_if_not_exists(activation_dir)\n",
    "utils.make_dir_if_not_exists(working_dir)\n",
    "utils.make_dir_if_not_exists(cav_dir)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]\n",
    "\n",
    "target = 'fire engine'  \n",
    "concepts = [\"red-c\",\"yellow-c\",\"blue-c\",\"green-c\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9645a",
   "metadata": {},
   "source": [
    "## Step 2: Defining the Model\n",
    "\n",
    "**GRAPH_PATH:** path to where the trained model is stored.\n",
    "\n",
    "**LABEL_PATH:** path to where the labels are stored. Each line contains one class, and they are ordered with respect to their index in the logit layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746e45d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TensorFlow session.\n",
    "sess = utils.create_session()\n",
    "\n",
    "# GRAPH_PATH is where the trained model is stored.\n",
    "GRAPH_PATH = source_dir + \"/inception5h/tensorflow_inception_graph.pb\"\n",
    "\n",
    "# LABEL_PATH is where the labels are stored. \n",
    "LABEL_PATH = source_dir + \"/inception5h/imagenet_comp_graph_label_strings.txt\"\n",
    "\n",
    "#Creating the GoogleNet model\n",
    "mymodel = model.GoogleNetWrapper_public(sess,\n",
    "                                        GRAPH_PATH,\n",
    "                                        LABEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170b0a6",
   "metadata": {},
   "source": [
    "## Step 3: Run TCAV\n",
    "\n",
    "The code is split into two sections. The first section is defining the activations for all bottleneck and concept combinations. This is done to allow for parallelization of the TCAV run. The second section runs the actual TCAV using the activations defined in the first section and creates visualizations of the importance of each concept.\n",
    "\n",
    "Some important parameters to consider in these sections are:\n",
    "\n",
    "**max_examples:** the maximum number of images used for each concept, target and random folder.\n",
    "\n",
    "**num_random_exp:** the number of random folders (`random500_0`, `random500_1`,...) to include in the run. This represent the number of experiments completed to confirm the legitimacy of the concept direction.\n",
    "\n",
    "### 3.1: Creating activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_generator = act_gen.ImageActivationGenerator(mymodel, source_dir, activation_dir, max_examples=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c235ea6a",
   "metadata": {},
   "source": [
    "### 3.2: Running TCAV and Visualizing Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl\n",
    "absl.logging.set_verbosity(0)\n",
    "num_random_exp=8\n",
    "\n",
    "## only running num_random_exp = 8 to save some time. The paper number are reported for 500 random runs. \n",
    "for alpha in alphas:\n",
    "    alpha = [alpha]\n",
    "    mytcav = tcav.TCAV(sess,\n",
    "                       target,\n",
    "                       concepts,\n",
    "                       bottlenecks,\n",
    "                       act_generator,\n",
    "                       alpha,\n",
    "                       cav_dir=cav_dir,\n",
    "                       num_random_exp=num_random_exp)\n",
    "    print ('Running for: ', alpha,'. This may take a while... Go get coffee!')\n",
    "    results = mytcav.run(run_parallel=False)\n",
    "    print ('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils_plot.plot_results(results, num_random_exp=num_random_exp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
