{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5900a9ba",
   "metadata": {},
   "source": [
    "# Running TCAV for Fire Engine Data\n",
    "\n",
    "This is a notebook that shows an example on how to run the TCAV library to predict which concepts are most important in the prediction of the contents of an image. This example focuses on using colors (red, yellow, green and blue) as human interpretable concepts in the prediction of Fire Engine images using GoogleNet.\n",
    "\n",
    "## Installing Packages\n",
    "Make sure to have all the required packages before running by executing the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6beae100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The filename, directory name, or volume label syntax is incorrect.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4cdb4f",
   "metadata": {},
   "source": [
    "## Downloading Data\n",
    "The data used in the TCAV library is split into three categories: \n",
    "> **Targets:** The imagenet object category we are interested in (in this case that is fire engine)\n",
    "\n",
    "> **Concepts:** The human comprehendable concepts used in the analysis\n",
    "\n",
    "> **Random folders:** Random data obtained from imagenet\n",
    "\n",
    "### Classes and Random Folders Data\n",
    "To download the class data and the random folders data, start by downloading the [imagenet dataset](https://www.kaggle.com/competitions/imagenet-object-localization-challenge/data). For the Fire Engine example, the class that was used was `fire engine`. The random folders were also extraced from the same dataset by running the following command:\n",
    "\n",
    "> python random_gen.py\n",
    "\n",
    "ATH SKOÐA BETUR?\n",
    "\n",
    "### Concept Data\n",
    "To get the color concept data used in the Fire Engine example run the following commands (Make sure to change the source_dir argument):\n",
    "\n",
    "> cd tcav/tcav_examples/image_models/imagenet\n",
    "\n",
    "> python download_and_make_datasets.py --source_dir=YOUR_PATH --number_of_images_per_folder=50\n",
    "\n",
    "## Importing Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bf6be8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatically reload all changed code\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef1a9fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tcav.activation_generator as act_gen\n",
    "import tcav.cav as cav\n",
    "import tcav.model  as model\n",
    "import tcav.tcav as tcav\n",
    "import tcav.utils as utils\n",
    "import tcav.utils_plot as utils_plot # utils_plot requires matplotlib\n",
    "import os \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579c682",
   "metadata": {},
   "source": [
    "## Step 1: Defining Parameters and Creating Local Folders\n",
    "\n",
    "In the cell below a few variables are defined that will be used throughout the notebook. \n",
    "\n",
    "**activation_dir:** directory to store activations\n",
    "\n",
    "**cav_dir:** directory to store CAVs\n",
    "\n",
    "**bottlenecks:** the intermediate layers in your model included for TCAV.\n",
    "\n",
    "**target, concepts:** the same as explained in the Downloading Data section above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "686d4591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REMEMBER TO UPDATE YOUR_PATH (where images, models are)!\n"
     ]
    }
   ],
   "source": [
    "print ('REMEMBER TO UPDATE YOUR_PATH (where images, models are)!')\n",
    "  \n",
    "project_dir = 'tcav_dir'\n",
    "# the name of the parent directory that results are stored (only if you want to cache)\n",
    "project_name = 'tcav_class_test'\n",
    "working_dir = \"/tmp/\" + project_dir + '/' + project_name\n",
    "# where activations are stored (only if your act_gen_wrapper does so)\n",
    "activation_dir =  working_dir + '/activations/'\n",
    "# where CAVs are stored. \n",
    "# You can say None if you don't wish to store any.\n",
    "cav_dir = working_dir + '/cavs/'\n",
    "# where the images live.\n",
    "\n",
    "# TODO: replace 'YOUR_PATH' with path to downloaded models and images. \n",
    "source_dir = 'YOUR_PATH'\n",
    "bottlenecks = [ 'mixed3a', 'mixed3b','mixed4a', 'mixed4b','mixed4c','mixed4d','mixed4e','mixed5a','mixed5b', 'logit']  # @param \n",
    "\n",
    "utils.make_dir_if_not_exists(activation_dir)\n",
    "utils.make_dir_if_not_exists(working_dir)\n",
    "utils.make_dir_if_not_exists(cav_dir)\n",
    "\n",
    "# this is a regularizer penalty parameter for linear classifier to get CAVs. \n",
    "alphas = [0.1]\n",
    "\n",
    "target = 'fire engine'  \n",
    "concepts = [\"red-c\",\"yellow-c\",\"blue-c\",\"green-c\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e9645a",
   "metadata": {},
   "source": [
    "## Step 2: Defining the Model\n",
    "\n",
    "**GRAPH_PATH:** path to where the trained model is stored.\n",
    "\n",
    "**LABEL_PATH:** path to where the labels are stored. Each line contains one class, and they are ordered with respect to their index in the logit layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "746e45d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aragorn\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1769: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "NewRandomAccessFile failed to Create/Open: YOUR_PATH/inception5h/imagenet_comp_graph_label_strings.txt : The system cannot find the path specified.\r\n; No such process",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18076/2864157806.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Creating the GoogleNet model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m mymodel = model.GoogleNetWrapper_public(sess,\n\u001b[0m\u001b[0;32m     12\u001b[0m                                         \u001b[0mGRAPH_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                                         LABEL_PATH)\n",
      "\u001b[1;32m~\\Documents\\haskoli\\DTU\\Semester3\\DeepLearning\\InterpretabilityUsingTCAV\\tcav\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess, model_saved_path, labels_path)\u001b[0m\n\u001b[0;32m    338\u001b[0m     )\n\u001b[0;32m    339\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     super(GoogleNetWrapper_public, self).__init__(\n\u001b[0m\u001b[0;32m    341\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m         \u001b[0mmodel_saved_path\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\haskoli\\DTU\\Semester3\\DeepLearning\\InterpretabilityUsingTCAV\\tcav\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, sess, model_fn_path, labels_path, image_shape, endpoints_dict, scope)\u001b[0m\n\u001b[0;32m    244\u001b[0m                endpoints_dict, scope):\n\u001b[0;32m    245\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPublicImageModelWrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m     self.ends = PublicImageModelWrapper.import_graph(\n\u001b[0;32m    248\u001b[0m         model_fn_path, endpoints_dict, self.image_value_range, scope=scope)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m    112\u001b[0m       \u001b[0mstring\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstring\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mregular\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m--> 114\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preread_check\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m       \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36m_preread_check\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m         raise errors.PermissionDeniedError(None, None,\n\u001b[0;32m     75\u001b[0m                                            \"File isn't open for reading\")\n\u001b[1;32m---> 76\u001b[1;33m       self._read_buf = _pywrap_file_io.BufferedInputStream(\n\u001b[0m\u001b[0;32m     77\u001b[0m           compat.path_to_str(self.__name), 1024 * 512)\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: NewRandomAccessFile failed to Create/Open: YOUR_PATH/inception5h/imagenet_comp_graph_label_strings.txt : The system cannot find the path specified.\r\n; No such process"
     ]
    }
   ],
   "source": [
    "# Create TensorFlow session.\n",
    "sess = utils.create_session()\n",
    "\n",
    "# GRAPH_PATH is where the trained model is stored.\n",
    "GRAPH_PATH = source_dir + \"/inception5h/tensorflow_inception_graph.pb\"\n",
    "\n",
    "# LABEL_PATH is where the labels are stored. \n",
    "LABEL_PATH = source_dir + \"/inception5h/imagenet_comp_graph_label_strings.txt\"\n",
    "\n",
    "#Creating the GoogleNet model\n",
    "mymodel = model.GoogleNetWrapper_public(sess,\n",
    "                                        GRAPH_PATH,\n",
    "                                        LABEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170b0a6",
   "metadata": {},
   "source": [
    "# Step 3: \n",
    "SKRIFA MEIRA HÉR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "act_generator = act_gen.ImageActivationGenerator(mymodel, source_dir, activation_dir, max_examples=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee93326",
   "metadata": {},
   "source": [
    "# Step 4: Run TCAV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7328975e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl\n",
    "absl.logging.set_verbosity(0)\n",
    "num_random_exp=8\n",
    "\n",
    "## only running num_random_exp = 10 to save some time. The paper number are reported for 500 random runs. \n",
    "for alpha in alphas:\n",
    "    alpha = [alpha]\n",
    "    mytcav = tcav.TCAV(sess,\n",
    "                       target,\n",
    "                       concepts,\n",
    "                       bottlenecks,\n",
    "                       act_generator,\n",
    "                       alpha,\n",
    "                       cav_dir=cav_dir,\n",
    "                       num_random_exp=num_random_exp)#10)\n",
    "    print ('Running for: ', alpha,'. This may take a while... Go get coffee!')\n",
    "    results = mytcav.run(run_parallel=False)\n",
    "    utils_plot.plot_results2(results, num_random_exp=num_random_exp, alpha=alpha)\n",
    "    print ('done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
